2020-03-27 09:41:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: customcrawler)
2020-03-27 09:41:03 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.2, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 18.9.0, Python 3.8.1 (v3.8.1:1b293b6006, Dec 18 2019, 14:08:53) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform macOS-10.11.6-x86_64-i386-64bit
2020-03-27 09:41:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'customcrawler', 'CLOSESPIDER_PAGECOUNT': '100', 'CLOSESPIDER_TIMEOUT': '60', 'CONCURRENT_REQUESTS': 32, 'DEPTH_PRIORITY': 1, 'LOG_FILE': 'logs/customcrawler/toscrapespiderax/f869e94a6fe011ea8c646c4008956c78.log', 'NEWSPIDER_MODULE': 'customcrawler.spiders', 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue', 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue', 'SPIDER_MODULES': ['customcrawler.spiders']}
2020-03-27 09:41:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats']
2020-03-27 09:41:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-03-27 09:41:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-03-27 09:41:03 [scrapy.middleware] INFO: Enabled item pipelines:
['customcrawler.pipelines.ScrapyAppPipeline']
2020-03-27 09:41:03 [scrapy.core.engine] INFO: Spider opened
2020-03-27 09:43:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-03-27 09:43:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2020-03-27 09:44:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/> (referer: None)
2020-03-27 09:44:24 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://lovdata.no/info/personvern> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-03-27 09:44:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/personvern#cookies> (referer: https://lovdata.no/)
2020-03-27 09:44:24 [amqp] DEBUG: Start from server, version: 0.9, properties: {'capabilities': {'publisher_confirms': True, 'exchange_exchange_bindings': True, 'basic.nack': True, 'consumer_cancel_notify': True, 'connection.blocked': True, 'consumer_priorities': True, 'authentication_failure_close': True, 'per_consumer_qos': True, 'direct_reply_to': True}, 'cluster_name': 'rabbit@Pratiks-MacBook-Pro', 'copyright': 'Copyright (c) 2007-2020 Pivotal Software, Inc.', 'information': 'Licensed under the MPL 1.1. Website: https://rabbitmq.com', 'platform': 'Erlang/OTP 22.3', 'product': 'RabbitMQ', 'version': '3.8.3'}, mechanisms: [b'PLAIN', b'AMQPLAIN'], locales: ['en_US']
2020-03-27 09:44:24 [amqp] DEBUG: using channel_id: 1
2020-03-27 09:44:24 [amqp] DEBUG: Channel open
2020-03-27 09:44:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/personvern>
{'extracted_url': 'https://lovdata.no/info/personvern'}
2020-03-27 09:44:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/dommer> (referer: https://lovdata.no/)
2020-03-27 09:44:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/dommer>
{'extracted_url': 'https://lovdata.no/register/dommer'}
2020-03-27 09:44:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/tariffavtaler> (referer: https://lovdata.no/)
2020-03-27 09:44:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/tariffavtaler>
{'extracted_url': 'https://lovdata.no/register/tariffavtaler'}
2020-03-27 09:44:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://lovdata.no/dokument/SPH/sph-2020> from <GET https://lovdata.no/sph>
2020-03-27 09:44:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/forskrifter> (referer: https://lovdata.no/)
2020-03-27 09:44:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/lovtidend> (referer: https://lovdata.no/)
2020-03-27 09:44:26 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://grunnloven.lovdata.no/> from <GET http://grunnloven.lovdata.no>
2020-03-27 09:44:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/forskrifter>
{'extracted_url': 'https://lovdata.no/register/forskrifter'}
2020-03-27 09:44:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/loverEngelsk> (referer: https://lovdata.no/)
2020-03-27 09:44:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/lovtidend>
{'extracted_url': 'https://lovdata.no/register/lovtidend'}
2020-03-27 09:44:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/loverEngelsk>
{'extracted_url': 'https://lovdata.no/register/loverEngelsk'}
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/forskrifterEngelsk> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/dommerEngelsk> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/tjenester/pro/> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/forskrifterEngelsk>
{'extracted_url': 'https://lovdata.no/register/forskrifterEngelsk'}
2020-03-27 09:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/dommerEngelsk>
{'extracted_url': 'https://lovdata.no/register/dommerEngelsk'}
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/pro/auth/student> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/tjenester/pro/>
{'extracted_url': 'https://lovdata.no/tjenester/pro/'}
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/tjenester/varsling> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/pro/auth/student>
{'extracted_url': 'https://lovdata.no/pro/auth/student'}
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/stortingsvedtak> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/tjenester/varsling>
{'extracted_url': 'https://lovdata.no/tjenester/varsling'}
2020-03-27 09:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/api> (referer: https://lovdata.no/)
2020-03-27 09:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/stortingsvedtak>
{'extracted_url': 'https://lovdata.no/register/stortingsvedtak'}
2020-03-27 09:44:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/api>
{'extracted_url': 'https://lovdata.no/info/api'}
2020-03-27 09:44:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/advokater/> (referer: https://lovdata.no/)
2020-03-27 09:44:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/22juli> (referer: https://lovdata.no/)
2020-03-27 09:44:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/advokater/>
{'extracted_url': 'https://lovdata.no/advokater/'}
2020-03-27 09:44:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/22juli>
{'extracted_url': 'https://lovdata.no/info/22juli'}
2020-03-27 09:44:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/tjenester/tidsskrift> (referer: https://lovdata.no/)
2020-03-27 09:44:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/tjenester/tidsskrift>
{'extracted_url': 'https://lovdata.no/tjenester/tidsskrift'}
2020-03-27 09:44:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/brukeravtale> (referer: https://lovdata.no/)
2020-03-27 09:44:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/brukeravtale>
{'extracted_url': 'https://lovdata.no/info/brukeravtale'}
2020-03-27 09:44:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/redaktoransvar> (referer: https://lovdata.no/)
2020-03-27 09:44:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/redaktoransvar>
{'extracted_url': 'https://lovdata.no/info/redaktoransvar'}
2020-03-27 09:44:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/publikasjoner> (referer: https://lovdata.no/)
2020-03-27 09:44:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/eosAvtalen> (referer: https://lovdata.no/)
2020-03-27 09:44:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/publikasjoner>
{'extracted_url': 'https://lovdata.no/publikasjoner'}
2020-03-27 09:44:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/eosAvtalen>
{'extracted_url': 'https://lovdata.no/register/eosAvtalen'}
2020-03-27 09:44:31 [scrapy.core.engine] INFO: Closing spider (closespider_timeout)
2020-03-27 09:44:31 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 21 pages/min), scraped 20 items (at 20 items/min)
2020-03-27 09:44:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/eli/> (referer: https://lovdata.no/)
2020-03-27 09:44:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/kontakt> (referer: https://lovdata.no/)
2020-03-27 09:44:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/rss> (referer: https://lovdata.no/)
2020-03-27 09:44:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/eli/>
{'extracted_url': 'https://lovdata.no/eli/'}
2020-03-27 09:44:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/kontakt>
{'extracted_url': 'https://lovdata.no/info/kontakt'}
2020-03-27 09:44:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/> (referer: https://lovdata.no/)
2020-03-27 09:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/rss>
{'extracted_url': 'https://lovdata.no/info/rss'}
2020-03-27 09:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/>
{'extracted_url': 'https://lovdata.no/'}
2020-03-27 09:44:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/forskrifter_med_heimel_i_koronaloven/2682> (referer: https://lovdata.no/)
2020-03-27 09:44:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/lenker> (referer: https://lovdata.no/)
2020-03-27 09:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/forskrifter_med_heimel_i_koronaloven/2682>
{'extracted_url': 'https://lovdata.no/artikkel/forskrifter_med_heimel_i_koronaloven/2682'}
2020-03-27 09:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/lenker>
{'extracted_url': 'https://lovdata.no/info/lenker'}
2020-03-27 09:44:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/oversikt_ny_regulering_knytt_til_koronaviruset/2669> (referer: https://lovdata.no/)
2020-03-27 09:44:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/SPH/sph-2020> (referer: https://lovdata.no/)
2020-03-27 09:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/oversikt_ny_regulering_knytt_til_koronaviruset/2669>
{'extracted_url': 'https://lovdata.no/artikkel/oversikt_ny_regulering_knytt_til_koronaviruset/2669'}
2020-03-27 09:44:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/SPH/sph-2020>
{'extracted_url': 'https://lovdata.no/dokument/SPH/sph-2020'}
2020-03-27 09:44:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://grunnloven.lovdata.no/> (referer: None)
2020-03-27 09:44:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://lovdata.no/pro/> from <GET https://lovdata.no/pro>
2020-03-27 09:44:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://grunnloven.lovdata.no/>
{'extracted_url': 'https://grunnloven.lovdata.no/'}
2020-03-27 09:44:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/eksamen> (referer: https://lovdata.no/)
2020-03-27 09:44:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/eksamen>
{'extracted_url': 'https://lovdata.no/info/eksamen'}
2020-03-27 09:44:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/NL/lov/1997-02-28-19> (referer: https://lovdata.no/)
2020-03-27 09:44:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/NL/lov/1997-02-28-19>
{'extracted_url': 'https://lovdata.no/dokument/NL/lov/1997-02-28-19'}
2020-03-27 09:44:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/NL/lov/2008-06-27-71> (referer: https://lovdata.no/)
2020-03-27 09:44:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/NL/lov/2008-06-27-71>
{'extracted_url': 'https://lovdata.no/dokument/NL/lov/2008-06-27-71'}
2020-03-27 09:44:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/NL/lov/1997-06-13-44> (referer: https://lovdata.no/)
2020-03-27 09:44:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/NL/lov/1997-06-13-44>
{'extracted_url': 'https://lovdata.no/dokument/NL/lov/1997-06-13-44'}
2020-03-27 09:44:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/NL/lov/2005-06-17-62> (referer: https://lovdata.no/)
2020-03-27 09:44:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/NL/lov/2005-06-17-62>
{'extracted_url': 'https://lovdata.no/dokument/NL/lov/2005-06-17-62'}
2020-03-27 09:44:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/ekstraordinaert_statsrad_18__mars_2020/2676> (referer: https://lovdata.no/)
2020-03-27 09:44:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/ekstraordinaert_statsrad_18__mars_2020/2676>
{'extracted_url': 'https://lovdata.no/artikkel/ekstraordinaert_statsrad_18__mars_2020/2676'}
2020-03-27 09:44:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikler> (referer: https://lovdata.no/)
2020-03-27 09:44:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikler>
{'extracted_url': 'https://lovdata.no/artikler'}
2020-03-27 09:44:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/gjeldande_reglar_karantene_etter_opphald_i_utlandet/2674> (referer: https://lovdata.no/)
2020-03-27 09:44:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/gjeldande_reglar_karantene_etter_opphald_i_utlandet/2674>
{'extracted_url': 'https://lovdata.no/artikkel/gjeldande_reglar_karantene_etter_opphald_i_utlandet/2674'}
2020-03-27 09:44:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/register/lover> (referer: https://lovdata.no/)
2020-03-27 09:44:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/register/lover>
{'extracted_url': 'https://lovdata.no/register/lover'}
2020-03-27 09:44:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/info/om_lovdata> (referer: https://lovdata.no/)
2020-03-27 09:44:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/info/om_lovdata>
{'extracted_url': 'https://lovdata.no/info/om_lovdata'}
2020-03-27 09:44:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/ekstraordinaert_statsrad_15__mars_2020/2671> (referer: https://lovdata.no/)
2020-03-27 09:44:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/ekstraordinaert_statsrad_15__mars_2020/2671>
{'extracted_url': 'https://lovdata.no/artikkel/ekstraordinaert_statsrad_15__mars_2020/2671'}
2020-03-27 09:44:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/riksadvokatens_brev_om_straff_ved_smittevern-lovbrot/2675> (referer: https://lovdata.no/)
2020-03-27 09:44:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/riksadvokatens_brev_om_straff_ved_smittevern-lovbrot/2675>
{'extracted_url': 'https://lovdata.no/artikkel/riksadvokatens_brev_om_straff_ved_smittevern-lovbrot/2675'}
2020-03-27 09:44:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/NL/lov/2005-05-20-28> (referer: https://lovdata.no/)
2020-03-27 09:44:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/NL/lov/2005-05-20-28>
{'extracted_url': 'https://lovdata.no/dokument/NL/lov/2005-05-20-28'}
2020-03-27 09:44:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/LTI/forskrift/2020-03-24-446> (referer: https://lovdata.no/)
2020-03-27 09:44:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/LTI/forskrift/2020-03-24-446>
{'extracted_url': 'https://lovdata.no/dokument/LTI/forskrift/2020-03-24-446'}
2020-03-27 09:44:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/LTI/forskrift/2020-03-23-445> (referer: https://lovdata.no/)
2020-03-27 09:44:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/LTI/forskrift/2020-03-23-445>
{'extracted_url': 'https://lovdata.no/dokument/LTI/forskrift/2020-03-23-445'}
2020-03-27 09:45:31 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 24 pages/min), scraped 44 items (at 24 items/min)
2020-03-27 09:46:31 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 0 pages/min), scraped 44 items (at 0 items/min)
2020-03-27 09:46:34 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2020-03-27 09:47:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/reglar_om_karantene_isolasjon_og_forbod_mot_overnatting_pa_fritidseigedom_mv_/2672> (referer: https://lovdata.no/)
2020-03-27 09:47:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/reglar_om_karantene_isolasjon_og_forbod_mot_overnatting_pa_fritidseigedom_mv_/2672>
{'extracted_url': 'https://lovdata.no/artikkel/reglar_om_karantene_isolasjon_og_forbod_mot_overnatting_pa_fritidseigedom_mv_/2672'}
2020-03-27 09:47:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/artikkel/statsrad_20__mars_2020/2679> (referer: https://lovdata.no/)
2020-03-27 09:47:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/artikkel/statsrad_20__mars_2020/2679>
{'extracted_url': 'https://lovdata.no/artikkel/statsrad_20__mars_2020/2679'}
2020-03-27 09:47:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://lovdata.no/dokument/LTI/forskrift/2020-03-25-447> (referer: https://lovdata.no/)
2020-03-27 09:47:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://lovdata.no/dokument/LTI/forskrift/2020-03-25-447>
{'extracted_url': 'https://lovdata.no/dokument/LTI/forskrift/2020-03-25-447'}
2020-03-27 09:47:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://lovdata.no/register/lokaleForskrifter> (failed 1 times): User timeout caused connection failure: Getting https://lovdata.no/register/lokaleForskrifter took longer than 180.0 seconds..
2020-03-27 09:47:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://lovdata.no/register/traktater> (failed 1 times): User timeout caused connection failure: Getting https://lovdata.no/register/traktater took longer than 180.0 seconds..
2020-03-27 09:47:31 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 3 pages/min), scraped 47 items (at 3 items/min)
2020-03-27 09:47:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://lovdata.no/artikkel/statsrad_13__mars_2020/2670> (failed 1 times): User timeout caused connection failure: Getting https://lovdata.no/artikkel/statsrad_13__mars_2020/2670 took longer than 180.0 seconds..
2020-03-27 09:47:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://lovdata.no/dokument/LTI/forskrift/2020-03-26-448> (failed 1 times): User timeout caused connection failure: Getting https://lovdata.no/dokument/LTI/forskrift/2020-03-26-448 took longer than 180.0 seconds..
2020-03-27 09:50:21 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/twisted/internet/defer.py", line 1416, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/twisted/python/failure.py", line 491, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scrapy/core/downloader/handlers/http11.py", line 351, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lovdata.no/dokument/LTI/forskrift/2020-03-26-448 took longer than 180.0 seconds..

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1245, in _execute_context
    self.dialect.do_execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 581, in do_execute
    cursor.execute(statement, parameters)
psycopg2.DatabaseError: SSL SYSCALL error: Operation timed out


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/pratikaher/ScrapyProjects/customcrawler/customcrawler/pipelines.py", line 84, in close_spider
    session.commit()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1027, in commit
    self.transaction.commit()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 494, in commit
    self._prepare_impl()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 473, in _prepare_impl
    self.session.flush()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2470, in flush
    self._flush(objects)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2608, in _flush
    transaction.rollback(_capture_exception=True)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 68, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 153, in reraise
    raise value
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2568, in _flush
    flush_context.execute()
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 586, in execute
    persistence.save_obj(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 239, in save_obj
    _emit_insert_statements(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    result = cached_connections[connection].execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 982, in execute
    return meth(self, multiparams, params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 287, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1095, in _execute_clauseelement
    ret = self._execute_context(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1249, in _execute_context
    self._handle_dbapi_exception(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1476, in _handle_dbapi_exception
    util.raise_from_cause(sqlalchemy_exception, exc_info)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 398, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 152, in reraise
    raise value.with_traceback(tb)
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1245, in _execute_context
    self.dialect.do_execute(
  File "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 581, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.DatabaseError: (psycopg2.DatabaseError) SSL SYSCALL error: Operation timed out

[SQL: INSERT INTO main_timetocrawl (job_data_id, domain_name, time_to_crawl) VALUES (%(job_data_id)s, %(domain_name)s, %(time_to_crawl)s) RETURNING main_timetocrawl.id]
[parameters: {'job_data_id': '6526', 'domain_name': 'lovdata.no', 'time_to_crawl': datetime.timedelta(seconds=404, microseconds=758987)}]
(Background on this error at: http://sqlalche.me/e/4xp6)
2020-03-27 09:50:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 4,
 'downloader/request_bytes': 18834,
 'downloader/request_count': 55,
 'downloader/request_method_count/GET': 55,
 'downloader/response_bytes': 619532,
 'downloader/response_count': 51,
 'downloader/response_status_count/200': 48,
 'downloader/response_status_count/301': 2,
 'downloader/response_status_count/302': 1,
 'dupefilter/filtered': 1672,
 'finish_reason': 'closespider_timeout',
 'finish_time': datetime.datetime(2020, 3, 27, 4, 20, 21, 726003),
 'item_scraped_count': 47,
 'log_count/DEBUG': 107,
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'memusage/max': 112103424,
 'memusage/startup': 73220096,
 'request_depth_max': 2,
 'response_received_count': 48,
 'retry/count': 4,
 'retry/reason_count/twisted.internet.error.TimeoutError': 4,
 'scheduler/dequeued': 55,
 'scheduler/dequeued/memory': 55,
 'scheduler/enqueued': 3730,
 'scheduler/enqueued/memory': 3730,
 'start_time': datetime.datetime(2020, 3, 27, 4, 13, 31, 571801)}
2020-03-27 09:50:21 [scrapy.core.engine] INFO: Spider closed (closespider_timeout)
